import pandas as pd
import numpy as np
import random
from deap import base, creator, tools, algorithms
import os
import shutil
import cv2
import albumentations as A

TARGET_TOTAL_IMAGES = 70 #‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ augmentation
NEW_IMAGES = 10  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ

# --- Load old data ---
df_old = pd.read_csv('./old_data/trainset.csv') # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏Å‡πà‡∏≤
df_new = pd.read_csv('./new_data/new_train.csv') # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡∏°‡πà
df_test = pd.read_csv('./test_data/test.csv') # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡∏°‡πà
df_notpra = pd.read_csv('./notpra/trainnotpra.csv') # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏û‡∏£‡∏∞

old_counts = df_old['name'].value_counts()
pra_names = old_counts.index.tolist()
pra_image_counts = old_counts.values
num_classes = len(pra_names)
total_notpra = 0
# --- ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û ---
SOURCE_IMAGE_OLD = 'old_data/old_data/'  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡πà‡∏≤
SOURCE_IMAGE_NEW = 'new_data/new_data/'  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏û‡∏£‡∏∞‡πÉ‡∏´‡∏°‡πà
SOURCE_IMAGE_TEST = 'test_data/test_img/'  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏ó‡∏™
SOURCE_IMAGE_NOTPRA = 'notpra/notpra/'  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏û‡∏£‡∏∞

EXPORT_DIR = 'combined'             # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏ß‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ö‡πÄ‡∏Å‡πà‡∏≤
IMAGE_EXPORT_DIR = os.path.join(EXPORT_DIR, 'train_new') # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏£‡∏ô
IMAGE_EXPORT_TEST = os.path.join(EXPORT_DIR, 'images_test') # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏™
os.makedirs(IMAGE_EXPORT_DIR, exist_ok=True) # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏£‡∏ô
os.makedirs(IMAGE_EXPORT_TEST, exist_ok=True) # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏™
df_export = df_new.copy()
df_export_test = df_test.copy()


transform = A.Compose([
    A.Rotate(limit=360, p=0.5),
    A.Blur(blur_limit=3, p=0.3),
    A.RandomBrightnessContrast(p=0.4),
    A.GaussNoise(p=0.2),
    # A.RandomCrop(width=200, height=200, p=0.2),
    A.RandomScale(scale_limit=(0.8, 1.2), p=0.2),
])

def augment_image(row, src_dir, export_dir, transform, n=2): 
    new_rows = []
    original_path = os.path.join(src_dir, row['filename'])

    image = cv2.imread(original_path)
    if image is None:
        print(f"‚ùå ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {original_path}")
        return []

    for i in range(n):
        transformed = transform(image=image)
        aug_image = transformed['image']
#jpg
        base_name = os.path.splitext(row['filename'])[0]  # ‡πÄ‡∏ä‡πà‡∏ô 'train_15'
        new_filename = f"{base_name}_copy{i+1}.png"
        new_path = os.path.join(export_dir, new_filename)

        cv2.imwrite(new_path, aug_image)

        # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        new_row = row.copy()
        new_row['filename'] = new_filename
        new_rows.append(new_row)
        print(f"‚úÖ Augmented: {new_filename} ‡∏à‡∏≤‡∏Å {row['filename']}")
    return new_rows

def init_individual():
    return [random.randint(1, count) for count in pra_image_counts]

def fitness(individual):
    total = sum(individual) + NEW_IMAGES
    if total > TARGET_TOTAL_IMAGES:
        return -1000,
    
    diversity_score = len([i for i in individual if i > 0]) / num_classes  # ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏û‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå
    balance_score = -np.std(individual)  # ‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
    return diversity_score * 100 + balance_score,

def custom_mutate(individual): #‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏£‡∏∞‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏á‡∏Ñ‡πå
    for i in range(len(individual)):
        if random.random() < 0.3:  # indpb = 0.2
            max_available = pra_image_counts[i]
            if max_available >= 50:
                individual[i] = random.randint(50, max_available)
            elif max_available > 0:
                individual[i] = random.randint(1, max_available)
            else:
                individual[i] = 0
    return individual,

def copy_images(df, source_dir, export_dir):
    for idx, row in df.iterrows():
        image_file = row['filename']
        src_path = os.path.join(source_dir, image_file)
        dst_path = os.path.join(export_dir, image_file)

        if os.path.exists(src_path):
            shutil.copy(src_path, dst_path)
            print(f"‚úÖ ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å: {image_file} ‡πÑ‡∏õ‡∏¢‡∏±‡∏á {export_dir}")
        else:
            print(f"‚ùó ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏†‡∏≤‡∏û: {src_path} - {source_dir}")

def augment_folder(df,csv_path,IMAGE_EXPORT_DIR,transform,n):
    augmented_rows = []
    for idx, row in df.iterrows():
        new_rows = augment_image(row, IMAGE_EXPORT_DIR, IMAGE_EXPORT_DIR, transform, n=n)
        augmented_rows.extend(new_rows)
    
    if augmented_rows:
        df_augmented = pd.DataFrame(augmented_rows)
        df_combined = pd.concat([df, df_augmented], ignore_index=True)
        df_combined.to_csv(csv_path, index=False)
        print(f"\nüß™ Augmentation ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(df_augmented)} ‡∏†‡∏≤‡∏û")
        print(f"üìÑ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï CSV ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {csv_path}")

if len(old_counts) > 0:
    print(f"üìä ‡∏°‡∏µ‡∏û‡∏£‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {num_classes} ‡∏≠‡∏á‡∏Ñ‡πå")

    # --- Genetic Algorithm Setup ---
    creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMax)

    toolbox = base.Toolbox()

    toolbox.register("individual", tools.initIterate, creator.Individual, init_individual)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    # --- Fitness Function ---
    toolbox.register("evaluate", fitness)
    toolbox.register("mate", tools.cxTwoPoint)
    toolbox.register("mutate", custom_mutate)
    toolbox.register("select", tools.selTournament, tournsize=3)

    # --- Run GA ---
    population = toolbox.population(n=50)
    result = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.3, ngen=40, verbose=False)

    # --- Best Individual ---
    best = tools.selBest(population, k=1)[0]
    selected_pra = [(pra_names[i], best[i]) for i in range(num_classes) if best[i] > 0]

    # --- Export selected subset ---
    df_sampled_list = []
    for name, num in selected_pra:
        df_subset = df_old[df_old['name'] == name]
        if len(df_subset) >= num:
            df_sampled = df_subset.sample(num, random_state=42)
            df_sampled_list.append(df_sampled)

    if df_sampled_list:
        df_sampled_ga = pd.concat(df_sampled_list, ignore_index=True)

        print(f"üéØ Selected {len(df_sampled_ga)} old images from GA")
        print("üß† ‡∏û‡∏£‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤:")
        for name, num in selected_pra:
            print(f" - {name}: {num} ‡∏£‡∏π‡∏õ")
            total_notpra = num

        # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏Å‡πà‡∏≤
        copy_images(df_sampled_ga, SOURCE_IMAGE_OLD, IMAGE_EXPORT_DIR)

        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ß‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏£‡∏∞‡πÉ‡∏´‡∏°‡πà
        df_export = pd.concat([df_sampled_ga, df_new], ignore_index=True)
    else:
        print("‚ö†Ô∏è GA ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏î‡∏à‡∏≤‡∏Å‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡πà‡∏≤ ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")

else:
    print("‚ö†Ô∏è ‡∏£‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏á‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡πà‡∏≤")

# --- ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà ---
copy_images(df_new, SOURCE_IMAGE_NEW, IMAGE_EXPORT_DIR)

# --- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≤‡∏Å df_sampled_ga ---
csv_path = os.path.join(EXPORT_DIR, 'trainset.csv')
df_export.to_csv(csv_path, index=False)

df_combined = pd.read_csv(csv_path)
# --- ‡∏ó‡∏≥ Augmentation ‡πÑ‡∏ü‡∏•‡πå train---
augment_folder(df_combined, csv_path, IMAGE_EXPORT_DIR, transform, n=100)  # augment ‡∏†‡∏≤‡∏û n = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏≠‡∏átrain


# ----‡∏™‡∏∏‡πà‡∏°notpra‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ ----
df_selected_notpra = df_notpra.sample(n=total_notpra*100, random_state=42)
print(f"üìà ‡πÑ‡∏î‡πâ notpra ‡∏£‡∏ß‡∏° {len(df_selected_notpra)} ‡∏£‡∏π‡∏õ (target = {total_notpra})")
# ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏†‡∏≤‡∏û notpra ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå train_new
copy_images(df_selected_notpra, SOURCE_IMAGE_NOTPRA, IMAGE_EXPORT_DIR)

# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• notpra ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö df_export
df_existing = pd.read_csv(csv_path)
df_export_combined = pd.concat([df_existing, df_selected_notpra], ignore_index=True)
df_export_combined.to_csv(csv_path, index=False)

#  ---- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏ó‡∏™ -----------
copy_images(df_test, SOURCE_IMAGE_TEST, IMAGE_EXPORT_TEST)

csv_test_path = os.path.join(EXPORT_DIR, 'test.csv')
df_export_test.to_csv(csv_test_path, index=False)
df_combined_test = pd.read_csv(csv_test_path)

# --- ‡∏ó‡∏≥ Augmentation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏™ ---
augment_folder(df_combined_test, csv_test_path, IMAGE_EXPORT_TEST, transform, n=10)  # augment ‡∏†‡∏≤‡∏û n = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏Ç‡∏≠‡∏átest

print(f"\n‚úÖ ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {EXPORT_DIR}")
print(f"üìÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {csv_path}")